{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ASIRRA base notebook for the Green AI - PSL Week - 2024**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Deyht/green_ai/blob/main/opt_cnn/ASIRRA_base_notebook_Green_AI_PSL.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Link to the CIANNA github repository**\n",
        "https://github.com/Deyht/CIANNA"
      ],
      "metadata": {
        "id": "JfKCrIlDu-E0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CIANNA installation**"
      ],
      "metadata": {
        "id": "vIXMFIFmvYzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query GPU allocation and properties\n",
        "\n",
        "If nvidia-smi fail, it might indicate that you launched the colab session whithout GPU reservation.  \n",
        "To change the type of reservation go to \"Runtime\"->\"Change runtime type\" and select \"GPU\" as your hardware accelerator."
      ],
      "metadata": {
        "id": "Ke8s2bCZvk1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvidia-smi\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/NVIDIA/cuda-samples/\n",
        "\n",
        "cd /content/cuda-samples/Samples/1_Utilities/deviceQuery/\n",
        "\n",
        "make SMS=\"50 60 70 80\"\n",
        "\n",
        "./deviceQuery | grep Capability | cut -c50- > ~/cuda_infos.txt\n",
        "./deviceQuery | grep \"CUDA Driver Version / Runtime Version\" | cut -c57- >> ~/cuda_infos.txt\n",
        "\n",
        "cd ~/"
      ],
      "metadata": {
        "id": "AHq06Uwk49Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are granted a GPU that supports high FP16 compute scaling (e.g the Tesla T4), it is advised to change the mixed_precision parameter in the prediction to \"FP16C_FP32A\".  \n",
        "See the detail description on mixed precision support with CIANNA on the [Systeme Requirements](https://github.com/Deyht/CIANNA/wiki/1\\)-System-Requirements) wiki page."
      ],
      "metadata": {
        "id": "tZ-lmHiRBFwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clone CIANNA git repository"
      ],
      "metadata": {
        "id": "A1SJ6-x8vqsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "git clone https://github.com/Deyht/CIANNA\n",
        "\n",
        "cd CIANNA"
      ],
      "metadata": {
        "id": "_uptvrov55YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling CIANNA for the allocated GPU generation\n",
        "\n",
        "There is no guaranteed forward or backward compatibility between Nvidia GPU generation, and some capabilities are generation specific. For these reasons, CIANNA must be provided the platform GPU generation at compile time.\n",
        "The following cell will automatically update all the necessary files based on the detected GPU, and compile CIANNA."
      ],
      "metadata": {
        "id": "JYGPC3OUv0td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "mult=\"10\"\n",
        "cat ~/cuda_infos.txt\n",
        "comp_cap=\"$(sed '1!d' ~/cuda_infos.txt)\"\n",
        "cuda_vers=\"$(sed '2!d' ~/cuda_infos.txt)\"\n",
        "\n",
        "lim=\"11.1\"\n",
        "old_arg=$(awk '{if ($1 < $2) print \"-D CUDA_OLD\";}' <<<\"${cuda_vers} ${lim}\")\n",
        "\n",
        "sm_val=$(awk '{print $1*$2}' <<<\"${mult} ${comp_cap}\")\n",
        "\n",
        "gen_val=$(awk '{if ($1 >= 80) print \"-D GEN_AMPERE\"; else if($1 >= 70) print \"-D GEN_VOLTA\";}' <<<\"${sm_val}\")\n",
        "\n",
        "sed -i \"s/.*arch=sm.*/\\\\t\\tcuda_arg=\\\"\\$cuda_arg -D CUDA -D comp_CUDA -lcublas -lcudart -arch=sm_$sm_val $old_arg $gen_val\\\"/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" compile.cp\n",
        "sed -i \"s/\\/cuda-[0-9][0-9].[0-9]/\\/cuda-$cuda_vers/g\" src/python_module_setup.py\n",
        "\n",
        "./compile.cp CUDA PY_INTERF\n",
        "\n",
        "mv src/build/lib.linux-x86_64-* src/build/lib.linux-x86_64"
      ],
      "metadata": {
        "id": "HGJUvmWW7YE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing CIANNA installation\n",
        "\n",
        "**IMPORTANT NOTE**   \n",
        "CIANNA is mainly used in a script fashion and was not designed to run in notebooks. Every cell code that directly invokes CIANNA functions must be run as a script to avoid possible errors.  \n",
        "To do so, the cell must have the following structure.\n",
        "\n",
        "```\n",
        "%%shell\n",
        "\n",
        "cd /content/CIANNA\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "[... your python code ...]\n",
        "\n",
        "EOF\n",
        "```\n",
        "\n",
        "This syntax allows one to easily edit python code in the notebook while running the cell as a script. Note that all the notebook variables can not be accessed by the cell in this context.\n"
      ],
      "metadata": {
        "id": "vbnBhbIL8wv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "\n",
        "#Strictly equivalent to ex_script.py in the CIANNA repo\n",
        "\n",
        "cd /content/CIANNA/examples/MNIST\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import sys, glob\n",
        "sys.path.insert(0,glob.glob('/content/CIANNA/src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "############################################################################\n",
        "##              Data reading (your mileage may vary)\n",
        "############################################################################\n",
        "\n",
        "def i_ar(int_list):\n",
        "\treturn np.array(int_list, dtype=\"int\")\n",
        "\n",
        "def f_ar(float_list):\n",
        "\treturn np.array(float_list, dtype=\"float32\")\n",
        "\n",
        "if(not os.path.isdir(\"mnist_dat\")):\n",
        "\tos.system(\"wget https://share.obspm.fr/s/EkYR5B2Wc2gNis3/download/mnist.tar.gz\")\n",
        "\tos.system(\"tar -xvzf mnist.tar.gz\")\n",
        "\n",
        "print (\"Reading inputs ... \", end = \"\", flush=True)\n",
        "\n",
        "#Loading binary files\n",
        "data = np.fromfile(\"mnist_dat/mnist_input.dat\", dtype=\"float32\")\n",
        "data = np.reshape(data, (80000,28*28))\n",
        "target = np.fromfile(\"mnist_dat/mnist_target.dat\", dtype=\"float32\")\n",
        "target = np.reshape(target, (80000,10))\n",
        "\n",
        "\n",
        "data_train = data[:60000,:]\n",
        "data_valid = data[60000:70000,:]\n",
        "data_test  = data[70000:80000,:]\n",
        "\n",
        "target_train = target[:60000,:]\n",
        "target_valid = target[60000:70000,:]\n",
        "target_test  = target[70000:80000,:]\n",
        "\n",
        "print (\"Done !\", flush=True)\n",
        "\n",
        "############################################################################\n",
        "##               CIANNA network construction and use\n",
        "############################################################################\n",
        "\n",
        "#Details about the functions and parameters are given in the GitHub Wiki\n",
        "\n",
        "cnn.init(in_dim=i_ar([28,28]), in_nb_ch=1, out_dim=10,\n",
        "\t\tbias=0.1, b_size=16, comp_meth=\"C_CUDA\", #Change to C_BLAS or C_NAIV\n",
        "\t\tdynamic_load=1, mixed_precision=\"FP32C_FP32A\")\n",
        "\n",
        "cnn.create_dataset(\"TRAIN\", size=60000, input=data_train, target=target_train)\n",
        "cnn.create_dataset(\"VALID\", size=10000, input=data_valid, target=target_valid)\n",
        "cnn.create_dataset(\"TEST\", size=10000, input=data_test, target=target_test)\n",
        "\n",
        "#Python side datasets are not required anymore, they can be released to save RAM\n",
        "#del (data_train, target_train, data_valid, target_valid, data_test, target_test)\n",
        "\n",
        "#Used to load a saved network at a given iteration\n",
        "load_step = 0\n",
        "if(load_step > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%(load_step), load_step)\n",
        "else:\n",
        "\tcnn.conv(f_size=i_ar([5,5]), nb_filters=8 , padding=i_ar([2,2]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([5,5]), nb_filters=16, padding=i_ar([2,2]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.dense(nb_neurons=256, activation=\"RELU\", drop_rate=0.5)\n",
        "\tcnn.dense(nb_neurons=128, activation=\"RELU\", drop_rate=0.2)\n",
        "\tcnn.dense(nb_neurons=10, strict_size=1, activation=\"SMAX\")\n",
        "\n",
        "\n",
        "#To create a latex table and associated pdf with the current architecture\n",
        "#cnn.print_arch_tex(\"./arch/\", \"arch\", activation=1)\n",
        "\n",
        "cnn.train(nb_iter=10, learning_rate=0.004, momentum=0.8, confmat=1, save_every=0)\n",
        "cnn.perf_eval()\n",
        "\n",
        "#Uncomment to save network prediction\n",
        "#cnn.forward(repeat=1, drop_mode=\"AVG_MODEL\")\n",
        "\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "2L-7ZffT9Ayq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ASIRRA**\n",
        "\n",
        "The ASIRRA (Animal Species Image Recognition for Restricting Access) is a dataset that was originaly used for CAPTCHA and HIP (Human Interactive Proofs).\n",
        "\n",
        "The dataset comprises 25000 images of variable resolution (averaging around 350x500) and perfectly distributed over the two classes \"Cat\" and \"Dog\". For this course, we provide a resized to 256x256 and squared version of the dataset so it can fit into the limited amount of Colab RAM more easily."
      ],
      "metadata": {
        "id": "gd2waB3JYNkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downloading and visualizing the data\n"
      ],
      "metadata": {
        "id": "kULtlVy8Y5UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/\n",
        "\n",
        "#Manually upload the directory to github if not yet opened\n",
        "git clone https://github.com/Deyht/green_ai"
      ],
      "metadata": {
        "id": "mjcrByRgYof3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/green_ai/opt_cnn/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "from aux_fct import *\n",
        "\n",
        "init_data_gen(0)\n",
        "\n",
        "print(\"\\nOrdered validation examples\")\n",
        "create_val_batch()\n",
        "\n",
        "print(\"Create visualization of the validation dataset\")\n",
        "visual_val(8,4)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "-PsyIg0sZmSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/green_ai/opt_cnn/\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "im = Image.open(\"val_mosaic.jpg\")\n",
        "plt.figure(figsize=(8,4), dpi=200)\n",
        "plt.imshow(im)\n",
        "plt.gca().axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xwExEJTXZygB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training a network\n",
        "\n",
        "You can modify whatever you find necessary to obtimize the mixed accuracy/efficiency/size metric. The only rule is to not use external data and outside pretrained model (you can still reload a model you trained here and modified part of its architecture to not restart from scratch every time you change something)."
      ],
      "metadata": {
        "id": "6ZeV1bvjRS4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%shell\n",
        "\n",
        "cd /content/green_ai/opt_cnn/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "from threading import Thread\n",
        "from aux_fct import *\n",
        "import gc, sys, glob\n",
        "\n",
        "#Comment to access system wide install\n",
        "sys.path.insert(0,glob.glob('/content/CIANNA/src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "\n",
        "def data_augm():\n",
        "\tinput_data, targets = create_train_batch()\n",
        "\tcnn.delete_dataset(\"TRAIN_buf\", silent=1)\n",
        "\tcnn.create_dataset(\"TRAIN_buf\", nb_images_per_iter, input_data[:,:], targets[:,:], silent=1)\n",
        "\treturn\n",
        "\n",
        "\n",
        "total_iter = 300\n",
        "nb_iter_per_augm = 1\n",
        "if(nb_iter_per_augm > 1):\n",
        "\tshuffle_frequency = 1\n",
        "else:\n",
        "\tshuffle_frequency = 0\n",
        "\n",
        "load_iter = 0\n",
        "\n",
        "start_iter = int(load_iter / nb_iter_per_augm)\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=3, out_dim=nb_class,\n",
        "\t\tbias=0.1, b_size=16, comp_meth='C_CUDA', dynamic_load=1,\n",
        "\t\tmixed_precision=\"FP32C_FP32A\", adv_size=30)\n",
        "\n",
        "init_data_gen()\n",
        "\n",
        "input_val, targets_val = create_val_batch()\n",
        "cnn.create_dataset(\"VALID\", nb_keep_val, input_val[:,:], targets_val[:,:])\n",
        "cnn.create_dataset(\"TEST\", nb_keep_val, input_val[:,:], targets_val[:,:])\n",
        "del (input_val, targets_val)\n",
        "gc.collect()\n",
        "\n",
        "input_data, targets = create_train_batch()\n",
        "cnn.create_dataset(\"TRAIN\", nb_images_per_iter, input_data[:,:], targets[:,:])\n",
        "\n",
        "if(load_iter > 0):\n",
        "\tcnn.load(\"net_save/net0_s%04d.dat\"%load_iter, load_iter, bin=1)\n",
        "else:\n",
        "\tcnn.conv(f_size=i_ar([5,5]), nb_filters=8 , padding=i_ar([2,2]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.conv(f_size=i_ar([5,5]), nb_filters=16, padding=i_ar([2,2]), activation=\"RELU\")\n",
        "\tcnn.pool(p_size=i_ar([2,2]), p_type=\"MAX\")\n",
        "\tcnn.dense(nb_neurons=256, activation=\"RELU\", drop_rate=0.5)\n",
        "\tcnn.dense(nb_neurons=128, activation=\"RELU\", drop_rate=0.2)\n",
        "\tcnn.dense(nb_neurons=nb_class, strict_size=1, activation=\"SMAX\")\n",
        "\n",
        "cnn.print_arch_tex(\"./arch/\", \"arch\", activation=1, dropout=1)\n",
        "\n",
        "for run_iter in range(start_iter,int(total_iter/nb_iter_per_augm)):\n",
        "\n",
        "\tt = Thread(target=data_augm)\n",
        "\tt.start()\n",
        "\n",
        "\tcnn.train(nb_iter=nb_iter_per_augm, learning_rate=0.002, end_learning_rate=0.00003, shuffle_every=shuffle_frequency ,\\\n",
        "\t\t\t control_interv=20, confmat=1, momentum=0.9, lr_decay=0.0015, weight_decay=0.0005, save_every=20,\\\n",
        "\t\t\t silent=0, save_bin=1, TC_scale_factor=256.0)\n",
        "\n",
        "\tif(run_iter == start_iter):\n",
        "\t\tcnn.perf_eval()\n",
        "\n",
        "\tt.join()\n",
        "\tcnn.swap_data_buffers(\"TRAIN\")\n",
        "\n",
        "EOF\n"
      ],
      "metadata": {
        "id": "MvRhvumeRWZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate your model\n",
        "\n",
        "The following cell allow to evaluate the accuracy and compute performance of your model in inference mode. Change the number of parameters in the score_eval() function to obtain a proper projection of the score.\n",
        "\n",
        "Edit the corresponding Google Sheet to add you model result:  \n",
        "https://docs.google.com/spreadsheets/d/1tAqTIzOMzjzPbic5GtZ64X2f8fNdzuKFkC3-b9q76jc/edit?usp=sharing"
      ],
      "metadata": {
        "id": "quIkFmK1TLUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%shell\n",
        "\n",
        "cd /content/green_ai/opt_cnn/\n",
        "\n",
        "python3 - <<EOF\n",
        "\n",
        "import numpy as np\n",
        "from threading import Thread\n",
        "from aux_fct import *\n",
        "import gc, time, sys, glob\n",
        "\n",
        "#Comment to access system wide install\n",
        "sys.path.insert(0,glob.glob('/content/CIANNA/src/build/lib.*/')[-1])\n",
        "import CIANNA as cnn\n",
        "\n",
        "load_epoch = 300\n",
        "\n",
        "#Change image test mode in aux_fct to change network resolution in all functions\n",
        "init_data_gen(test_mode=1)\n",
        "\n",
        "cnn.init(in_dim=i_ar([image_size,image_size]), in_nb_ch=3, out_dim=nb_class,\n",
        "\tbias=0.1, b_size=16, comp_meth='C_CUDA', dynamic_load=1,\n",
        "\tmixed_precision=\"FP32C_FP32A\", adv_size=30, inference_only=1)\n",
        "\n",
        "#Compute on only half the validation set to reduce memory footprint\n",
        "input_test, targets_test = create_val_batch()\n",
        "cnn.create_dataset(\"TEST\", nb_keep_val, input_test[:,:], targets_test[:,:])\n",
        "\n",
        "del (input_test, targets_test)\n",
        "gc.collect()\n",
        "\n",
        "cnn.load(\"net_save/net0_s%04d.dat\"%load_epoch, load_epoch, bin=1)\n",
        "\n",
        "cnn.forward(repeat=1, no_error=1, saving=2, drop_mode=\"AVG_MODEL\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "cnn.forward(no_error=1, saving=2, drop_mode=\"AVG_MODEL\")\n",
        "end = time.perf_counter()\n",
        "\n",
        "cnn.perf_eval()\n",
        "cnn.print_arch_tex(\"./arch/\", \"arch\", activation=1, dropout=1)\n",
        "\n",
        "compute_time = (end-start)*1000 #in miliseconds\n",
        "score_eval(load_epoch,compute_time, 1090293)\n",
        "\n",
        "EOF"
      ],
      "metadata": {
        "id": "oMM45xmgTgFj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
